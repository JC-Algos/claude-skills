#!/usr/bin/env python3
"""
å¸‚å ´æŠ€è¡“åˆ†ææ¨¡çµ„ - Market Technical Analysis Module
Analyzes HK and US stocks with comprehensive TA indicators
"""

import os
import yfinance as yf
import pandas as pd
import pandas_ta as ta
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import json

# Import RRG and RS analyzer
try:
    from rrg_rs_analyzer import generate_rrg_chart, get_rs_ranking, format_rrg_report_zh, format_rs_report_zh, get_rrg_quadrant_zh
    RRG_RS_AVAILABLE = True
except ImportError:
    RRG_RS_AVAILABLE = False

class NumpyEncoder(json.JSONEncoder):
    """Custom encoder to handle numpy types"""
    def default(self, obj):
        if isinstance(obj, (np.integer, np.floating)):
            return float(obj)
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        if isinstance(obj, (np.bool_,)):
            return bool(obj)
        return super().default(obj)

class MarketAnalyzer:
    """Technical analysis for HK and US markets"""
    
    # Market suffixes
    MARKET_SUFFIX = {
        'HK': '.HK',
        'US': ''  # US stocks don't need suffix
    }
    
    def __init__(self):
        self.indicators = {}
        
    def get_symbol(self, ticker: str, market: str = 'US') -> str:
        """Convert ticker to Yahoo Finance format"""
        suffix = self.MARKET_SUFFIX.get(market.upper(), '')
        if market.upper() == 'HK' and not ticker.endswith('.HK'):
            # HK stocks need 4-digit format
            ticker = ticker.zfill(4) + suffix
        return ticker
    
    def fetch_data(self, ticker: str, market: str = 'US', period: str = '1y', interval: str = '1d') -> pd.DataFrame:
        """Fetch OHLCV data from Yahoo Finance"""
        symbol = self.get_symbol(ticker, market)
        try:
            data = yf.download(symbol, period=period, interval=interval, progress=False)
            if data.empty:
                raise ValueError(f"No data found for {symbol}")
            # Flatten multi-index columns if present
            if isinstance(data.columns, pd.MultiIndex):
                data.columns = data.columns.get_level_values(0)
            return data
        except Exception as e:
            raise ValueError(f"Failed to fetch {symbol}: {str(e)}")
    
    def calculate_emas(self, df: pd.DataFrame) -> Dict:
        """Calculate EMA 10, 20, 60, 200"""
        emas = {}
        for period in [10, 20, 60, 200]:
            col_name = f'EMA_{period}'
            df[col_name] = ta.ema(df['Close'], length=period)
            emas[period] = df[col_name].iloc[-1] if not df[col_name].isna().iloc[-1] else None
        
        # Determine trend
        close = df['Close'].iloc[-1]
        ema_10 = emas.get(10)
        ema_20 = emas.get(20)
        ema_60 = emas.get(60)
        ema_200 = emas.get(200)
        
        trend = self._analyze_trend(close, ema_10, ema_20, ema_60, ema_200)
        
        # Build EMA sequence string
        ema_values = [(10, ema_10), (20, ema_20), (60, ema_60), (200, ema_200)]
        sorted_emas = sorted(ema_values, key=lambda x: x[1] if x[1] else 0, reverse=True)
        sequence = ' > '.join([f"EMA{e[0]}" for e in sorted_emas if e[1] is not None])
        
        return {
            'values': {k: round(float(v), 2) if v is not None else None for k, v in emas.items()},
            'trend': trend,
            'trend_zh': self._trend_to_chinese(trend),
            'sequence': sequence
        }
    
    def _analyze_trend(self, close, ema_10, ema_20, ema_60, ema_200) -> str:
        """Analyze trend based on EMA alignment"""
        if None in [ema_10, ema_20, ema_60, ema_200]:
            return 'insufficient_data'
        
        # Check EMA sequence
        bullish_sequence = ema_10 > ema_20 > ema_60 > ema_200  # å¤šé ­æ’åˆ—
        bearish_sequence = ema_10 < ema_20 < ema_60 < ema_200  # ç©ºé ­æ’åˆ—
        long_term_bullish = ema_60 > ema_200  # é•·æœŸå¤šé ­
        long_term_bearish = ema_60 < ema_200  # é•·æœŸç©ºé ­
        short_term_bullish = ema_10 > ema_20  # çŸ­æœŸå¤šé ­
        short_term_bearish = ema_10 < ema_20  # çŸ­æœŸç©ºé ­
        
        # Full bullish alignment: å¤šé ­æ’åˆ—
        if bullish_sequence and close > ema_10:
            return 'bullish_alignment'
        # Full bearish alignment: ç©ºé ­æ’åˆ—
        elif bearish_sequence and close < ema_10:
            return 'bearish_alignment'
        # Long-term uptrend with short-term consolidation
        elif long_term_bullish and short_term_bearish:
            if close > ema_60:
                return 'uptrend_consolidation'
            else:
                return 'uptrend_correction'
        # Long-term downtrend with short-term bounce
        elif long_term_bearish and short_term_bullish:
            if close < ema_60:
                return 'downtrend_bounce'
            else:
                return 'downtrend_recovery'
        # Uptrend with all EMAs bullish
        elif long_term_bullish and short_term_bullish:
            if close > ema_10:
                return 'strong_uptrend'
            else:
                return 'uptrend_pullback'
        # Downtrend with all EMAs bearish
        elif long_term_bearish and short_term_bearish:
            if close < ema_10:
                return 'strong_downtrend'
            else:
                return 'downtrend_relief'
        # Transition phase
        else:
            return 'transition'
    
    def _trend_to_chinese(self, trend: str) -> str:
        """Convert trend to Chinese"""
        mapping = {
            'bullish_alignment': 'ğŸŸ¢ å¤šé ­æ’åˆ— (10>20>60>200)',
            'bearish_alignment': 'ğŸ”´ ç©ºé ­æ’åˆ— (10<20<60<200)',
            'strong_uptrend': 'ğŸ“ˆ å¼·å‹¢ä¸Šå‡ (å‡ç·šå¤šé ­)',
            'uptrend_pullback': 'ğŸ“ˆâ†˜ï¸ ä¸Šå‡è¶¨å‹¢å›èª¿',
            'uptrend_consolidation': 'ğŸ“ˆâ¸ï¸ ä¸Šå‡è¶¨å‹¢æ•´ç† (çŸ­æœŸå›èª¿ï¼Œé•·æœŸå¤šé ­)',
            'uptrend_correction': 'ğŸ“ˆâš ï¸ ä¸Šå‡è¶¨å‹¢ä¿®æ­£ (è·Œç ´60æ—¥ç·š)',
            'strong_downtrend': 'ğŸ“‰ å¼·å‹¢ä¸‹è·Œ (å‡ç·šç©ºé ­)',
            'downtrend_bounce': 'ğŸ“‰â†—ï¸ ä¸‹è·Œè¶¨å‹¢åå½ˆ (çŸ­æœŸå›å‡ï¼Œé•·æœŸç©ºé ­)',
            'downtrend_recovery': 'ğŸ“‰ğŸ”„ ä¸‹è·Œè¶¨å‹¢åè½‰å˜—è©¦',
            'downtrend_relief': 'ğŸ“‰â¸ï¸ ä¸‹è·Œè¶¨å‹¢å–˜æ¯',
            'transition': 'ğŸ”„ è¶¨å‹¢è½‰æ›æœŸ',
            'insufficient_data': 'âš ï¸ æ•¸æ“šä¸è¶³'
        }
        return mapping.get(trend, trend)
    
    def calculate_dmi_adx(self, df: pd.DataFrame) -> Dict:
        """Calculate DMI (DI+, DI-) and ADX for trend strength"""
        adx_data = ta.adx(df['High'], df['Low'], df['Close'], length=14)
        
        if adx_data is None or adx_data.empty:
            return {'error': 'Failed to calculate ADX/DMI'}
        
        # Get latest values
        adx = adx_data['ADX_14'].iloc[-1]
        di_plus = adx_data['DMP_14'].iloc[-1]
        di_minus = adx_data['DMN_14'].iloc[-1]
        
        # Previous values for trend change detection
        adx_prev = adx_data['ADX_14'].iloc[-2] if len(adx_data) > 1 else adx
        di_plus_prev = adx_data['DMP_14'].iloc[-2] if len(adx_data) > 1 else di_plus
        di_minus_prev = adx_data['DMN_14'].iloc[-2] if len(adx_data) > 1 else di_minus
        
        # Analyze trendiness
        trendiness = self._analyze_trendiness(adx, di_plus, di_minus, adx_prev, di_plus_prev, di_minus_prev)
        
        return {
            'ADX': round(float(adx), 2),
            'DI_plus': round(float(di_plus), 2),
            'DI_minus': round(float(di_minus), 2),
            'trendiness': trendiness,
            'trendiness_zh': self._trendiness_to_chinese(trendiness)
        }
    
    def _analyze_trendiness(self, adx, di_plus, di_minus, adx_prev, di_plus_prev, di_minus_prev) -> str:
        """Analyze trend strength and potential changes"""
        # ADX levels
        if adx > 40:
            strength = 'very_strong'
        elif adx > 25:
            strength = 'strong'
        elif adx > 20:
            strength = 'moderate'
        else:
            strength = 'weak'
        
        # Direction
        if di_plus > di_minus:
            direction = 'bullish'
        else:
            direction = 'bearish'
        
        # Trend change signals
        crossover = False
        if di_plus > di_minus and di_plus_prev <= di_minus_prev:
            crossover = 'bullish_crossover'
        elif di_minus > di_plus and di_minus_prev <= di_plus_prev:
            crossover = 'bearish_crossover'
        
        # ADX turning
        adx_rising = bool(adx > adx_prev)
        
        return {
            'strength': strength,
            'direction': direction,
            'crossover': crossover,
            'adx_rising': adx_rising
        }
    
    def _trendiness_to_chinese(self, trendiness: Dict) -> str:
        """Convert trendiness analysis to Chinese"""
        strength_map = {
            'very_strong': 'éå¸¸å¼·å‹¢',
            'strong': 'å¼·å‹¢',
            'moderate': 'ä¸­ç­‰',
            'weak': 'å¼±å‹¢/ç„¡è¶¨å‹¢'
        }
        direction_map = {
            'bullish': 'å¤šæ–¹ä¸»å°',
            'bearish': 'ç©ºæ–¹ä¸»å°'
        }
        
        result = f"è¶¨å‹¢å¼·åº¦: {strength_map.get(trendiness['strength'], trendiness['strength'])}\n"
        result += f"æ–¹å‘: {direction_map.get(trendiness['direction'], trendiness['direction'])}\n"
        
        if trendiness['crossover']:
            if trendiness['crossover'] == 'bullish_crossover':
                result += "âš ï¸ DI+ å‘ä¸Šç©¿è¶Š DI- (çœ‹æ¼²ä¿¡è™Ÿ)\n"
            else:
                result += "âš ï¸ DI- å‘ä¸Šç©¿è¶Š DI+ (çœ‹è·Œä¿¡è™Ÿ)\n"
        
        if trendiness['adx_rising']:
            result += "ADX ä¸Šå‡ä¸­ (è¶¨å‹¢åŠ å¼·)"
        else:
            result += "ADX ä¸‹é™ä¸­ (è¶¨å‹¢æ¸›å¼±)"
        
        return result
    
    def calculate_fibonacci(self, df: pd.DataFrame, lookback: int = 60) -> Dict:
        """Calculate Fibonacci retracement levels"""
        recent = df.tail(lookback)
        high = recent['High'].max()
        low = recent['Low'].min()
        diff = high - low
        
        # Standard Fibonacci levels
        levels = {
            '0.0% (é«˜é»)': high,
            '23.6%': high - diff * 0.236,
            '38.2%': high - diff * 0.382,
            '50.0%': high - diff * 0.5,
            '61.8%': high - diff * 0.618,
            '78.6%': high - diff * 0.786,
            '100.0% (ä½é»)': low
        }
        
        # Current price position
        close = df['Close'].iloc[-1]
        position = self._find_fib_position(close, levels)
        
        return {
            'high': round(high, 2),
            'low': round(low, 2),
            'levels': {k: round(v, 2) for k, v in levels.items()},
            'current_price': round(close, 2),
            'position': position,
            'position_zh': self._fib_position_to_chinese(position, close, levels)
        }
    
    def _find_fib_position(self, price, levels) -> str:
        """Find where current price sits relative to Fib levels"""
        sorted_levels = sorted(levels.values(), reverse=True)
        for i, level in enumerate(sorted_levels[:-1]):
            if price >= sorted_levels[i+1]:
                return f"between_{i}_{i+1}"
        return "below_all"
    
    def _fib_position_to_chinese(self, position: str, price: float, levels: Dict) -> str:
        """Convert Fib position to Chinese analysis"""
        level_names = list(levels.keys())
        level_values = list(levels.values())
        
        # Find nearest support and resistance
        supports = [v for v in level_values if v < price]
        resistances = [v for v in level_values if v > price]
        
        nearest_support = max(supports) if supports else None
        nearest_resistance = min(resistances) if resistances else None
        
        result = ""
        if nearest_resistance:
            # Find level name
            for name, val in levels.items():
                if val == nearest_resistance:
                    result += f"ğŸ“ ä¸Šæ–¹é˜»åŠ›: {name} @ {round(nearest_resistance, 2)}\n"
                    break
        
        if nearest_support:
            for name, val in levels.items():
                if val == nearest_support:
                    result += f"ğŸ“ ä¸‹æ–¹æ”¯æ’: {name} @ {round(nearest_support, 2)}"
                    break
        
        return result if result else "åƒ¹æ ¼åœ¨æ–æ³¢é‚£å¥‘ç¯„åœå¤–"
    
    def analyze_volume(self, df: pd.DataFrame) -> Dict:
        """Analyze volume patterns"""
        # Volume moving averages
        df['Vol_MA_20'] = df['Volume'].rolling(20).mean()
        
        current_vol = df['Volume'].iloc[-1]
        avg_vol = df['Vol_MA_20'].iloc[-1]
        vol_ratio = current_vol / avg_vol if avg_vol > 0 else 1
        
        # Volume trend (last 5 days)
        recent_vol = df['Volume'].tail(5).mean()
        prev_vol = df['Volume'].tail(10).head(5).mean()
        vol_trend = 'increasing' if recent_vol > prev_vol * 1.1 else ('decreasing' if recent_vol < prev_vol * 0.9 else 'stable')
        
        # Price-volume relationship
        price_change = (df['Close'].iloc[-1] - df['Close'].iloc[-2]) / df['Close'].iloc[-2] * 100
        
        if vol_ratio > 1.5 and price_change > 0:
            pv_signal = 'bullish_volume_breakout'
        elif vol_ratio > 1.5 and price_change < 0:
            pv_signal = 'bearish_volume_breakdown'
        elif vol_ratio < 0.7:
            pv_signal = 'low_volume_consolidation'
        else:
            pv_signal = 'normal'
        
        return {
            'current': int(current_vol),
            'avg_20': int(avg_vol) if not np.isnan(avg_vol) else None,
            'ratio': round(vol_ratio, 2),
            'trend': vol_trend,
            'signal': pv_signal,
            'analysis_zh': self._volume_to_chinese(vol_ratio, vol_trend, pv_signal, price_change)
        }
    
    def _volume_to_chinese(self, ratio, trend, signal, price_change) -> str:
        """Convert volume analysis to Chinese"""
        result = ""
        
        # Volume vs average
        if ratio > 2:
            result += "ğŸ”¥ æˆäº¤é‡ç•°å¸¸æ”¾å¤§ (>2x å¹³å‡)\n"
        elif ratio > 1.5:
            result += "ğŸ“ˆ æˆäº¤é‡æ˜é¡¯æ”¾å¤§\n"
        elif ratio > 1:
            result += "æˆäº¤é‡ç•¥é«˜æ–¼å¹³å‡\n"
        elif ratio > 0.7:
            result += "æˆäº¤é‡æ­£å¸¸\n"
        else:
            result += "ğŸ“‰ æˆäº¤é‡èç¸®\n"
        
        # Trend
        trend_map = {
            'increasing': 'è¿‘æœŸæˆäº¤é‡è¶¨å‹¢: æ”¾å¤§',
            'decreasing': 'è¿‘æœŸæˆäº¤é‡è¶¨å‹¢: èç¸®',
            'stable': 'è¿‘æœŸæˆäº¤é‡è¶¨å‹¢: ç©©å®š'
        }
        result += trend_map.get(trend, '') + "\n"
        
        # Signal interpretation
        signal_map = {
            'bullish_volume_breakout': 'âš ï¸ åƒ¹æ¼²é‡å¢ - å¯èƒ½çªç ´',
            'bearish_volume_breakdown': 'âš ï¸ åƒ¹è·Œé‡å¢ - å¯èƒ½ç ´ä½',
            'low_volume_consolidation': 'ä½é‡æ•´ç†ä¸­',
            'normal': 'é‡åƒ¹é…åˆæ­£å¸¸'
        }
        result += signal_map.get(signal, '')
        
        return result
    
    def analyze_candlestick(self, df: pd.DataFrame) -> Dict:
        """Analyze candlestick patterns"""
        patterns = []
        
        # Get last few candles
        last = df.iloc[-1]
        prev = df.iloc[-2] if len(df) > 1 else None
        
        o, h, l, c = last['Open'], last['High'], last['Low'], last['Close']
        body = abs(c - o)
        upper_wick = h - max(o, c)
        lower_wick = min(o, c) - l
        total_range = h - l
        
        # Doji
        if body < total_range * 0.1 and total_range > 0:
            patterns.append(('doji', 'åå­—æ˜Ÿ', 'neutral', 'å¸‚å ´çŒ¶è±«ä¸æ±ºï¼Œå¯èƒ½è®Šç›¤'))
        
        # Hammer (at potential bottom)
        if lower_wick > body * 2 and upper_wick < body * 0.5 and body > 0:
            patterns.append(('hammer', 'éŒ˜å­ç·š', 'bullish', 'å¯èƒ½è¦‹åº•ä¿¡è™Ÿ'))
        
        # Shooting star (at potential top)
        if upper_wick > body * 2 and lower_wick < body * 0.5 and body > 0:
            patterns.append(('shooting_star', 'å°„æ“Šä¹‹æ˜Ÿ', 'bearish', 'å¯èƒ½è¦‹é ‚ä¿¡è™Ÿ'))
        
        # Marubozu (strong candle)
        if body > total_range * 0.8 and total_range > 0:
            if c > o:
                patterns.append(('bullish_marubozu', 'å…‰é ­å…‰è…³é™½ç·š', 'bullish', 'å¼·å‹¢è²·ç›¤'))
            else:
                patterns.append(('bearish_marubozu', 'å…‰é ­å…‰è…³é™°ç·š', 'bearish', 'å¼·å‹¢è³£ç›¤'))
        
        # Engulfing patterns - check last 3 days for better detection
        # Allow small gap tolerance (1% of price)
        gap_tolerance = c * 0.01
        
        if len(df) >= 3:
            # Look back up to 3 days for engulfing patterns
            for lookback in range(1, min(4, len(df))):
                check_candle = df.iloc[-1 - lookback]
                check_body = abs(check_candle['Close'] - check_candle['Open'])
                
                # Bullish engulfing: find a red candle that current green candle engulfs
                is_check_red = check_candle['Close'] < check_candle['Open']
                is_current_green = c > o
                opens_near_or_below = o <= check_candle['Close'] + gap_tolerance
                closes_above = c >= check_candle['Open']
                body_larger = body > check_body * 1.5  # Current body at least 1.5x larger
                
                if is_check_red and is_current_green and opens_near_or_below and closes_above and body_larger:
                    if lookback == 1:
                        patterns.append(('bullish_engulfing', 'çœ‹æ¼²åå™¬', 'bullish', 'å¼·å‹¢åè½‰ä¿¡è™Ÿ'))
                    else:
                        patterns.append(('bullish_engulfing', f'çœ‹æ¼²åå™¬ ({lookback}æ—¥å‰)', 'bullish', f'åå™¬{lookback}æ—¥å‰é™°ç·šï¼Œå¼·å‹¢åè½‰'))
                    break  # Found one, stop looking
                
                # Bearish engulfing: find a green candle that current red candle engulfs
                is_check_green = check_candle['Close'] > check_candle['Open']
                is_current_red = c < o
                opens_near_or_above = o >= check_candle['Close'] - gap_tolerance
                closes_below = c <= check_candle['Open']
                
                if is_check_green and is_current_red and opens_near_or_above and closes_below and body_larger:
                    if lookback == 1:
                        patterns.append(('bearish_engulfing', 'çœ‹è·Œåå™¬', 'bearish', 'å¼±å‹¢åè½‰ä¿¡è™Ÿ'))
                    else:
                        patterns.append(('bearish_engulfing', f'çœ‹è·Œåå™¬ ({lookback}æ—¥å‰)', 'bearish', f'åå™¬{lookback}æ—¥å‰é™½ç·šï¼Œå¼±å‹¢åè½‰'))
                    break
        
        # Basic candle description
        if c > o:
            candle_type = 'é™½ç·š'
            change_pct = (c - o) / o * 100
        else:
            candle_type = 'é™°ç·š'
            change_pct = (o - c) / o * 100
        
        return {
            'type': candle_type,
            'body_pct': round(body / total_range * 100, 1) if total_range > 0 else 0,
            'patterns': patterns,
            'analysis_zh': self._candle_to_chinese(candle_type, patterns, change_pct)
        }
    
    def _candle_to_chinese(self, candle_type, patterns, change_pct) -> str:
        """Convert candlestick analysis to Chinese"""
        result = f"ğŸ“Š æœ€æ–°Kç·š: {candle_type}\n"
        
        if patterns:
            result += "\nğŸ•¯ï¸ ç™¼ç¾Kç·šå½¢æ…‹:\n"
            for p in patterns:
                name, zh_name, bias, desc = p
                emoji = 'ğŸŸ¢' if bias == 'bullish' else ('ğŸ”´' if bias == 'bearish' else 'âšª')
                result += f"  {emoji} {zh_name}: {desc}\n"
        else:
            result += "æœªç™¼ç¾æ˜é¡¯Kç·šå½¢æ…‹"
        
        return result
    
    def calculate_volume_profile(self, df: pd.DataFrame, num_bins: int = 50, value_area_pct: float = 0.70) -> Dict:
        """
        Calculate Volume Profile with VAL, VAH, and PoC
        
        Args:
            df: DataFrame with OHLCV data
            num_bins: Number of price bins for the profile
            value_area_pct: Percentage for value area (default 70%)
        
        Returns:
            Dict with PoC, VAH, VAL and profile data
        """
        if len(df) < 20:
            return {'error': 'Insufficient data for volume profile'}
        
        # Use typical price (HLC/3) for volume distribution
        df = df.copy()
        df['typical_price'] = (df['High'] + df['Low'] + df['Close']) / 3
        
        # Create price bins
        price_min = df['Low'].min()
        price_max = df['High'].max()
        bin_size = (price_max - price_min) / num_bins
        
        # Initialize volume profile
        profile = {}
        for i in range(num_bins):
            bin_low = price_min + (i * bin_size)
            bin_high = bin_low + bin_size
            bin_mid = (bin_low + bin_high) / 2
            profile[bin_mid] = 0
        
        # Distribute volume across price bins
        for idx, row in df.iterrows():
            low, high, vol = row['Low'], row['High'], row['Volume']
            if vol == 0 or np.isnan(vol):
                continue
            
            # Find bins that this candle spans
            for bin_mid in profile.keys():
                bin_low = bin_mid - (bin_size / 2)
                bin_high = bin_mid + (bin_size / 2)
                
                # Check if candle overlaps with bin
                if high >= bin_low and low <= bin_high:
                    # Calculate overlap percentage
                    overlap_low = max(low, bin_low)
                    overlap_high = min(high, bin_high)
                    candle_range = high - low if high > low else 1
                    overlap_pct = (overlap_high - overlap_low) / candle_range
                    profile[bin_mid] += vol * overlap_pct
        
        # Find Point of Control (PoC) - highest volume price level
        poc_price = max(profile, key=profile.get)
        poc_volume = profile[poc_price]
        
        # Calculate Value Area (VAH and VAL)
        total_volume = sum(profile.values())
        target_volume = total_volume * value_area_pct
        
        # Sort bins by distance from PoC
        sorted_bins = sorted(profile.items(), key=lambda x: abs(x[0] - poc_price))
        
        accumulated_volume = 0
        value_area_prices = []
        
        for price, vol in sorted_bins:
            accumulated_volume += vol
            value_area_prices.append(price)
            if accumulated_volume >= target_volume:
                break
        
        vah = max(value_area_prices)  # Value Area High
        val = min(value_area_prices)  # Value Area Low
        
        # Current price position relative to value area
        current_price = df['Close'].iloc[-1]
        
        if current_price > vah:
            position = 'above_va'
            position_zh = 'åœ¨åƒ¹å€¼å€ä¸Šæ–¹ (å¯èƒ½è¶…è²·)'
        elif current_price < val:
            position = 'below_va'
            position_zh = 'åœ¨åƒ¹å€¼å€ä¸‹æ–¹ (å¯èƒ½è¶…è³£)'
        elif abs(current_price - poc_price) < bin_size * 2:
            position = 'at_poc'
            position_zh = 'æ¥è¿‘æ§åˆ¶é» (PoC)'
        else:
            position = 'in_va'
            position_zh = 'åœ¨åƒ¹å€¼å€å…§'
        
        return {
            'poc': round(float(poc_price), 2),
            'vah': round(float(vah), 2),
            'val': round(float(val), 2),
            'current_price': round(float(current_price), 2),
            'position': position,
            'position_zh': position_zh,
            'analysis_zh': self._volume_profile_to_chinese(poc_price, vah, val, current_price, position)
        }
    
    def _volume_profile_to_chinese(self, poc, vah, val, current_price, position) -> str:
        """Convert volume profile to Chinese analysis"""
        result = f"""ğŸ“Š **æˆäº¤é‡åˆ†ä½ˆ (Volume Profile)**
â€¢ PoC (æ§åˆ¶é»): {round(poc, 2)}
â€¢ VAH (åƒ¹å€¼å€é«˜): {round(vah, 2)}
â€¢ VAL (åƒ¹å€¼å€ä½): {round(val, 2)}
â€¢ åƒ¹å€¼å€ç¯„åœ: {round(val, 2)} - {round(vah, 2)}

"""
        if position == 'above_va':
            result += "ğŸ“ ç¾åƒ¹åœ¨åƒ¹å€¼å€ä¸Šæ–¹\n"
            result += f"âš ï¸ è·VAH: {round(current_price - vah, 2)} (å¯èƒ½å›è½è‡³åƒ¹å€¼å€)\n"
            result += f"é—œæ³¨æ”¯æ’: VAH @ {round(vah, 2)}"
        elif position == 'below_va':
            result += "ğŸ“ ç¾åƒ¹åœ¨åƒ¹å€¼å€ä¸‹æ–¹\n"
            result += f"âš ï¸ è·VAL: {round(val - current_price, 2)} (å¯èƒ½åå½ˆè‡³åƒ¹å€¼å€)\n"
            result += f"é—œæ³¨é˜»åŠ›: VAL @ {round(val, 2)}"
        elif position == 'at_poc':
            result += "ğŸ“ ç¾åƒ¹æ¥è¿‘æ§åˆ¶é» (PoC)\n"
            result += "é€™æ˜¯æˆäº¤é‡æœ€é›†ä¸­çš„åƒ¹ä½ï¼Œé€šå¸¸æœ‰è¼ƒå¼·æ”¯æ’/é˜»åŠ›"
        else:
            result += "ğŸ“ ç¾åƒ¹åœ¨åƒ¹å€¼å€å…§\n"
            result += f"ä¸Šæ–¹é˜»åŠ›: VAH @ {round(vah, 2)}\n"
            result += f"ä¸‹æ–¹æ”¯æ’: VAL @ {round(val, 2)}"
        
        return result
    
    def full_analysis(self, ticker: str, market: str = 'US') -> Dict:
        """Run complete technical analysis"""
        try:
            # Fetch data (use 2 years for better volume profile)
            df = self.fetch_data(ticker, market, period='2y')
            
            # Get stock info
            symbol = self.get_symbol(ticker, market)
            stock = yf.Ticker(symbol)
            info = stock.info
            name = info.get('shortName', info.get('longName', ticker))
            
            # Run all analyses
            emas = self.calculate_emas(df.copy())
            dmi_adx = self.calculate_dmi_adx(df.copy())
            fibonacci = self.calculate_fibonacci(df.copy())
            volume = self.analyze_volume(df.copy())
            candlestick = self.analyze_candlestick(df.copy())
            volume_profile = self.calculate_volume_profile(df.copy())
            
            # Current price info
            current_price = df['Close'].iloc[-1]
            prev_close = df['Close'].iloc[-2] if len(df) > 1 else current_price
            change = current_price - prev_close
            change_pct = (change / prev_close) * 100
            
            # RRG and RS Analysis (if available)
            rrg_data = None
            rs_data = None
            if RRG_RS_AVAILABLE:
                try:
                    # Generate RRG chart - use CHART_DIR env var if set
                    chart_dir = os.environ.get('CHART_DIR', '/root/clawd/research/charts')
                    os.makedirs(chart_dir, exist_ok=True)
                    rrg_output_path = f'{chart_dir}/rrg_{ticker}_{market}_{datetime.now().strftime("%Y%m%d_%H%M%S")}.png'
                    rrg_data = generate_rrg_chart(ticker, market, output_path=rrg_output_path)
                except Exception as e:
                    rrg_data = {'success': False, 'error': str(e)}
                
                try:
                    # Get RS ranking
                    rs_data = get_rs_ranking(ticker, market)
                except Exception as e:
                    rs_data = {'success': False, 'error': str(e)}
            
            return {
                'success': True,
                'ticker': ticker,
                'market': market,
                'name': name,
                'price': {
                    'current': round(current_price, 2),
                    'change': round(change, 2),
                    'change_pct': round(change_pct, 2)
                },
                'ema': emas,
                'dmi_adx': dmi_adx,
                'fibonacci': fibonacci,
                'volume': volume,
                'candlestick': candlestick,
                'volume_profile': volume_profile,
                'rrg': rrg_data,
                'rs_ranking': rs_data,
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'ticker': ticker,
                'market': market
            }
    
    def generate_report_zh(self, analysis: Dict) -> str:
        """Generate Chinese analysis report"""
        if not analysis.get('success'):
            return f"âŒ åˆ†æå¤±æ•—: {analysis.get('error', 'æœªçŸ¥éŒ¯èª¤')}"
        
        report = f"""ğŸ“Š **{analysis['name']}** ({analysis['ticker']}.{analysis['market']})
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ’° **åƒ¹æ ¼è³‡è¨Š**
ç¾åƒ¹: {analysis['price']['current']}
æ¼²è·Œ: {analysis['price']['change']} ({analysis['price']['change_pct']:+.2f}%)

â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€

ğŸ“ˆ **è¶¨å‹¢åˆ†æ (EMA)**
{analysis['ema']['trend_zh']}
æ’åˆ—é †åº: {analysis['ema'].get('sequence', 'N/A')}
â€¢ EMA10: {analysis['ema']['values'].get(10, 0):.2f}
â€¢ EMA20: {analysis['ema']['values'].get(20, 0):.2f}
â€¢ EMA60: {analysis['ema']['values'].get(60, 0):.2f}
â€¢ EMA200: {analysis['ema']['values'].get(200, 0):.2f}

â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€

ğŸ“ **è¶¨å‹¢å¼·åº¦ (DMI/ADX)**
ADX: {analysis['dmi_adx'].get('ADX', 'N/A')}
DI+: {analysis['dmi_adx'].get('DI_plus', 'N/A')} | DI-: {analysis['dmi_adx'].get('DI_minus', 'N/A')}
{analysis['dmi_adx'].get('trendiness_zh', '')}

â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€

ğŸ“ **æ–æ³¢é‚£å¥‘é—œéµä½**
{analysis['fibonacci'].get('position_zh', '')}
â€¢ é«˜é»: {analysis['fibonacci']['high']}
â€¢ ä½é»: {analysis['fibonacci']['low']}

â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€

ğŸ“Š **æˆäº¤é‡åˆ†æ**
{analysis['volume'].get('analysis_zh', '')}

â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€

ğŸ“ˆ **æˆäº¤é‡åˆ†ä½ˆ (Volume Profile)**
{analysis.get('volume_profile', {}).get('analysis_zh', 'N/A')}

â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€

ğŸ•¯ï¸ **Kç·šå½¢æ…‹**
{analysis['candlestick'].get('analysis_zh', '')}
"""
        
        # Add RRG section if available
        if analysis.get('rrg') and analysis['rrg'].get('success'):
            rrg = analysis['rrg']
            quadrant_zh = get_rrg_quadrant_zh(rrg['quadrant']) if RRG_RS_AVAILABLE else rrg['quadrant']
            benchmark_zh = 'æ†ç”ŸæŒ‡æ•¸' if rrg['benchmark'] == '^HSI' else 'æ¨™æ™®500æŒ‡æ•¸'
            # RS-Ratio context: >100 = outperforming, <100 = underperforming
            ratio_context = "è´å¸‚å ´" if rrg['rs_ratio'] >= 100 else "è¼¸å¸‚å ´"
            # RS-Momentum context: >100 = strengthening, <100 = weakening
            momentum_context = "æ­£åœ¨å¢å¼·" if rrg['rs_momentum'] >= 100 else "æ­£åœ¨æ¸›å¼±"
            report += f"""
â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€

ğŸ“ˆ **è³‡ç”¢è¼ªå‹•**
â€¢ ç›¸å°å¼·åº¦æ¯”ç‡: {rrg['rs_ratio']} (ç›¸å°è¡¨ç¾{ratio_context} :100)
â€¢ ç›¸å°å¼·åº¦å‹•èƒ½: {rrg['rs_momentum']} (ç›¸å°è¡¨ç¾{momentum_context})
â€¢ è±¡é™: {quadrant_zh}
â€¢ åŸºæº–: {benchmark_zh}
"""
        
        # Add RS Ranking section if available
        if analysis.get('rs_ranking') and analysis['rs_ranking'].get('success'):
            rs = analysis['rs_ranking']
            rankings = rs.get('rankings', {})
            changes = rs.get('rank_changes', {})
            current = rankings.get('current', {})
            
            report += f"""
â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€

ğŸ“Š **ç›¸å°å¼·åº¦æ’å (Relative Strength Rank)**
â€¢ ç¾æ™‚æ’å: #{current.get('rank', 'N/A')}/{current.get('total_stocks', 'N/A')} (åˆ†æ•¸: {current.get('score', 'N/A')})
"""
            # Add historical changes
            for period in ['1d_ago', '2d_ago', '5d_ago', '10d_ago']:
                if period in rankings and rankings[period].get('rank'):
                    r = rankings[period]
                    change = changes.get(period, 0)
                    change_str = f"â†‘{change}" if change > 0 else (f"â†“{abs(change)}" if change < 0 else "â†’")
                    report += f"â€¢ {period.replace('_ago', 'æ—¥å‰')}: #{r['rank']} ({change_str})\n"
            
            # Removed: footnote about ticker not in original basket
        
        report += f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
â° åˆ†ææ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M')} UTC
ğŸ“Œ æ•¸æ“šé€±æœŸ: 2å¹´æ—¥ç·š
"""
        return report.strip()


# Flask API for n8n integration
def create_app():
    from flask import Flask, request, jsonify
    
    app = Flask(__name__)
    app.json.encoder = NumpyEncoder
    analyzer = MarketAnalyzer()
    
    @app.route('/health', methods=['GET'])
    def health():
        return jsonify({'status': 'ok', 'service': 'market-analyzer'})
    
    @app.route('/analyze', methods=['POST'])
    def analyze():
        """
        Analyze a stock
        Body: {"ticker": "AAPL", "market": "US"} or {"ticker": "0700", "market": "HK"}
        """
        data = request.json or {}
        ticker = data.get('ticker')
        market = data.get('market', 'US')
        
        if not ticker:
            return jsonify({'error': 'ticker is required'}), 400
        
        result = analyzer.full_analysis(ticker, market)
        return jsonify(result)
    
    @app.route('/analyze/report', methods=['POST'])
    def analyze_report():
        """Get analysis as formatted Chinese report"""
        data = request.json or {}
        ticker = data.get('ticker')
        market = data.get('market', 'US')
        
        if not ticker:
            return jsonify({'error': 'ticker is required'}), 400
        
        analysis = analyzer.full_analysis(ticker, market)
        report = analyzer.generate_report_zh(analysis)
        
        return jsonify({
            'success': analysis.get('success', False),
            'report': report,
            'raw': analysis
        })
    
    @app.route('/analyze/batch', methods=['POST'])
    def analyze_batch():
        """Analyze multiple stocks"""
        data = request.json or {}
        stocks = data.get('stocks', [])  # [{"ticker": "AAPL", "market": "US"}, ...]
        
        results = []
        for stock in stocks:
            ticker = stock.get('ticker')
            market = stock.get('market', 'US')
            if ticker:
                analysis = analyzer.full_analysis(ticker, market)
                report = analyzer.generate_report_zh(analysis)
                results.append({
                    'ticker': ticker,
                    'market': market,
                    'report': report,
                    'success': analysis.get('success', False)
                })
        
        return jsonify({'results': results, 'count': len(results)})
    
    @app.route('/analyze/telegram', methods=['POST'])
    def analyze_telegram():
        """Analyze and send directly to Telegram"""
        import subprocess
        
        data = request.json or {}
        ticker = data.get('ticker')
        market = data.get('market', 'US')
        chat_id = data.get('chat_id', '1016466977')  # Default to Jason's chat
        
        if not ticker:
            return jsonify({'error': 'ticker is required'}), 400
        
        analysis = analyzer.full_analysis(ticker, market)
        report = analyzer.generate_report_zh(analysis)
        
        # Send via clawdbot CLI
        try:
            result = subprocess.run(
                ['/usr/bin/clawdbot', 'message', 'send', 
                 '--channel', 'telegram', 
                 '--target', str(chat_id), 
                 '--message', report],
                capture_output=True,
                text=True,
                timeout=30
            )
            sent = result.returncode == 0
        except Exception as e:
            sent = False
        
        return jsonify({
            'success': analysis.get('success', False),
            'sent': sent,
            'ticker': ticker,
            'market': market
        })
    
    @app.route('/analyze/complete', methods=['POST'])
    def analyze_complete():
        """
        Complete analysis with TA report + Technical chart + RRG chart
        Returns all paths for consistent output
        """
        import subprocess
        
        data = request.json or {}
        ticker = data.get('ticker')
        market = data.get('market', 'US')
        
        if not ticker:
            return jsonify({'error': 'ticker is required'}), 400
        
        result = {
            'success': False,
            'ticker': ticker,
            'market': market,
            'report': '',
            'technical_chart': None,
            'rrg_chart': None
        }
        
        # 1. Run TA analysis and get formatted report
        analysis = analyzer.full_analysis(ticker, market)
        result['report'] = analyzer.generate_report_zh(analysis)
        result['success'] = analysis.get('success', False)
        result['raw'] = analysis
        
        # 2. Get RRG chart path from analysis (already generated in full_analysis)
        if analysis.get('rrg', {}).get('chart_path'):
            result['rrg_chart'] = analysis['rrg']['chart_path']
        
        # 3. Generate technical chart using venv python
        try:
            venv_python = '/root/clawd/projects/market-analyzer/venv/bin/python3'
            chart_result = subprocess.run(
                [venv_python, '/root/clawd/projects/market-analyzer/generate_chart.py',
                 ticker, '--market', market, '--period', '13mo'],
                capture_output=True,
                text=True,
                timeout=90,
                cwd='/root/clawd/projects/market-analyzer'
            )
            # Extract chart path from output
            import re
            for line in chart_result.stdout.split('\n'):
                match = re.search(r'(/root/clawd/research/charts/[^\s]+\.png)', line)
                if match:
                    result['technical_chart'] = match.group(1)
                    break
            if not result['technical_chart'] and chart_result.stderr:
                result['technical_chart_error'] = chart_result.stderr[:200]
        except Exception as e:
            result['technical_chart_error'] = str(e)
        
        return jsonify(result)
    
    @app.route('/analyze/full', methods=['POST'])
    def analyze_full():
        """
        Full analysis with TA + Perplexity news
        Requires PERPLEXITY_API_KEY environment variable
        """
        import subprocess
        import os
        
        data = request.json or {}
        ticker = data.get('ticker')
        market = data.get('market', 'US')
        chat_id = data.get('chat_id', '1016466977')
        include_news = data.get('include_news', True)
        
        if not ticker:
            return jsonify({'error': 'ticker is required'}), 400
        
        # Run TA analysis
        analysis = analyzer.full_analysis(ticker, market)
        ta_report = analyzer.generate_report_zh(analysis)
        
        # Try to get Perplexity news if API key is available
        news_report = ""
        if include_news and os.environ.get('PERPLEXITY_API_KEY'):
            try:
                from perplexity_client import PerplexityClient
                pplx = PerplexityClient()
                news = pplx.search_news(ticker, market)
                if news.get('success'):
                    news_report = f"""

ğŸ“° **æ–°èé¢åˆ†æ (Perplexity AI)**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

{news.get('content', 'N/A')}
"""
                    if news.get('citations'):
                        news_report += "\nğŸ“ è³‡æ–™ä¾†æº:\n"
                        for cite in news.get('citations', [])[:5]:
                            news_report += f"â€¢ {cite}\n"
            except Exception as e:
                news_report = f"\nâš ï¸ æ–°èç²å–å¤±æ•—: {str(e)}\n"
        elif include_news:
            news_report = "\nâš ï¸ æ–°èåŠŸèƒ½éœ€è¦è¨­ç½® PERPLEXITY_API_KEY\n"
        
        # Combine reports
        full_report = ta_report + news_report
        
        # Send to Telegram
        try:
            result = subprocess.run(
                ['/usr/bin/clawdbot', 'message', 'send', 
                 '--channel', 'telegram', 
                 '--target', str(chat_id), 
                 '--message', full_report],
                capture_output=True,
                text=True,
                timeout=60
            )
            sent = result.returncode == 0
        except Exception as e:
            sent = False
        
        return jsonify({
            'success': analysis.get('success', False),
            'sent': sent,
            'ticker': ticker,
            'market': market,
            'has_news': bool(news_report and 'Perplexity' in news_report)
        })
    
    return app


if __name__ == '__main__':
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == 'serve':
        # Run as API server
        app = create_app()
        port = int(sys.argv[2]) if len(sys.argv) > 2 else 5003
        print(f"Starting Market Analyzer API on port {port}...")
        app.run(host='0.0.0.0', port=port, debug=False)
    else:
        # CLI test
        analyzer = MarketAnalyzer()
        
        # Test with a US stock
        print("Testing AAPL (US)...")
        result = analyzer.full_analysis('AAPL', 'US')
        print(analyzer.generate_report_zh(result))
        
        print("\n" + "="*50 + "\n")
        
        # Test with a HK stock (Tencent)
        print("Testing 0700 (HK)...")
        result = analyzer.full_analysis('0700', 'HK')
        print(analyzer.generate_report_zh(result))
